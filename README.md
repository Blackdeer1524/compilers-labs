# Лабораторная работа № 1.3 «Объектно-ориентированный лексический анализатор»

## 1 Цель работы

Целью данной работы является приобретение навыка реализации лексического анализатора на объектно-ориентированном языке без применения каких-либо средств автоматизации решения задачи лексического анализа.

## 2 Задание

В лабораторной работе предлагается реализовать на объектно-ориентированном языке (Java, C++, Python и т.д.) две первые фазы стадии анализа: чтение входного потока и лексический анализ. При этом следует придерживаться схемы реализации объектно-ориентированного лексического анализатора, рассмотренной на лекции.

Допустимо делать лабораторную на функциональном языке программирования, реализуя токены различных лексических доменов при помощи алгебраических типов данных. Лексический анализатор при этом должен быть чистым: принимать исходный текст как строку и возвращать кортеж из списка токенов, таблицы идентификаторов, списка комментариев и списка ошибок.

Входной поток должен загружаться из файла (в UTF-8). В результате работы программы в стандартный поток вывода должны выдаваться описания распознанных лексем в формате

Тег (координаты фрагмента): атрибут лексемы

При этом для лексем, не имеющих атрибутов, нужно выводить только тег и координаты. Например,

```
IDENT (1, 2)-(1, 4): str
ASSIGN (1, 8)-(1, 9):
STRING (1, 11)-(1, 16): qwerty
```

Лексемы во входном файле могут разделяться пробельными символами (пробел, горизонтальная табуляция, маркеры окончания строки), а могут быть записаны слитно (если это не приводит к противоречиям).

Идентификаторы и числовые литералы не могут содержать внутри себя пробельных символов, если в задании явно не указано иного. Комментарии, строковые и символьные литералы могут содержать внутри себя пробельные символы.

Лексический анализатор должен иметь программный интерфейс для взаимодействия с парсером — метод nextToken() по образцу из лекций (допустимо использовать интерфейс итератора для выбранного ЯП, например, в C++ можно переопределить операции \* и ++). При реализации на чистых функциональных языках (и только на них) лексический анализатор может быть реализован как функция, возвращающая кортеж из списка токенов и списка сообщений (для некоторых вариантов: кортеж из списка токенов, списка сообщений и списка комментариев).

Входной файл может содержать ошибки, при обнаружении которых лексический анализатор должен выдавать сообщение с указанием координаты, восстанавливаться и продолжать работу.

Для лексических доменов должны вычисляться их атрибуты (если указанный лексический домен есть в варианте задания):

- для целых чисел атрибут должен быть целым числом наибольшей разрядности (например, в Java — long).
- для вещественных чисел атрибут должен быть вещественным числом (например, double в Java или C++),
- для идентификаторов — номер в таблице идентификаторов (см. слайды лекции),
- для строковых констант — значение, изображаемое самой строковой константой (т.е. без окружающих кавычек и с интерпретацией escape-последовательностей, если они есть в варианте задания),
- для комментариев токен не порождается, вместо этого координаты комментария помещается в список комментариев (см. слайды лекции).

Числовые литералы могут начинаться с нуля.

## 3 Индивидуальный вариант

- Строковые литералы: ограничены обратными кавычками, могут занимать несколько строчек текста, для включения обратной кавычки она удваивается.
- Числовые литералы: десятичные литералы представляют собой последовательности десятичных цифр, двоичные — последовательности нулей и единиц, оканчивающиеся буквой «b».
- Идентификаторы: последовательности десятичных цифр и знаков «?», «\*» и «|», не начинающиеся с цифры.
